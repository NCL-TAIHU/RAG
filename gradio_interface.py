import gradio as gr
import requests
import os
from loguru import logger
import pandas as pd
from typing import Dict, List, Tuple, Any

API_URL = os.getenv("API_URL", "http://localhost:8000")

def format_search_results(results: List[Dict[str, Any]]) -> str:
    if not results:
        return "âš ï¸ æ²’æœ‰æ‰¾åˆ°ç›¸é—œè«–æ–‡è³‡æ–™"
    table_md = "| # | è«–æ–‡æ¨™é¡Œ |\n|---|-----------|\n"
    for i, item in enumerate(results, 1):
        table_md += f"| {i} | {item.get('title', 'ç„¡æ¨™é¡Œ')} |\n"
    return table_md

def perform_search(query: str, method: str, sparse_weight: float, dense_weight: float, limit: int) -> Tuple[str, str]:
    try:
        payload = {
            "query": query,
            "method": method,
            "sparse_weight": sparse_weight,
            "dense_weight": dense_weight,
            "limit": limit
        }
        response = requests.post(f"{API_URL}/search", json=payload)
        if response.status_code != 200:
            return "", f"âŒ API è«‹æ±‚å¤±æ•—ï¼ˆç‹€æ…‹ç¢¼ {response.status_code}ï¼‰"
        data = response.json()
        results_markdown = format_search_results(data.get("results", []))
        llm_response = data.get("llm_response", "ï¼ˆç„¡å›æ‡‰ï¼‰")
        full_response = f"ğŸ“š **ç³»çµ±å›æ‡‰ï¼š**\n{llm_response}\n\nğŸ” **æœå°‹çµæœï¼š**\n{results_markdown}"
        return query, full_response
    except Exception as e:
        return "", f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"

def create_interface():
    with gr.Blocks(title="å°ç£åœ‹åœ–è«–æ–‡æœå°‹ GPT ä»‹é¢", theme=gr.themes.Soft()) as demo:
        gr.Markdown("## ğŸ“ åœ‹åœ–è«–æ–‡æ™ºæ…§æœå°‹ï¼ˆé¡ GPT ä»‹é¢ï¼‰")

        chatbot = gr.Chatbot(label="å°è©±æ­·å²", height=500, show_label=False)
        chat_history = gr.State([])  # å„²å­˜æ­·å²

        with gr.Row():
            with gr.Column():
                query_input = gr.Textbox(placeholder="è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ...", lines=2, label=None)
                send_btn = gr.Button("ğŸš€ é€å‡º", variant="primary")

        with gr.Accordion("âš™ï¸ é€²éšè¨­å®š", open=False):
            method = gr.Radio(["hybrid_search", "dense_search", "sparse_search"],
                              label="æœå°‹æ–¹æ³•", value="hybrid_search")
            sparse_weight = gr.Slider(0.0, 1.0, 0.5, step=0.1, label="ç¨€ç–å‘é‡æ¬Šé‡")
            dense_weight = gr.Slider(0.0, 1.0, 0.5, step=0.1, label="å¯†é›†å‘é‡æ¬Šé‡")
            limit = gr.Slider(1, 10, 5, step=1, label="é¡¯ç¤ºçµæœæ•¸é‡")

        def chat_and_search(query, method, sparse_weight, dense_weight, limit, history):
            user_query, system_reply = perform_search(query, method, sparse_weight, dense_weight, limit)
            if user_query:
                history.append([user_query, system_reply])
            return history, history

        send_btn.click(
            fn=chat_and_search,
            inputs=[query_input, method, sparse_weight, dense_weight, limit, chat_history],
            outputs=[chatbot, chat_history]
        )

    return demo

if __name__ == "__main__":
    demo = create_interface()
    port = int(os.getenv("GRADIO_PORT", 7860))
    demo.launch(server_name="0.0.0.0", server_port=port, share=True)
