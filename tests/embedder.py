import unittest
import sys
import os
import io
import numpy as np
import csv
from datetime import datetime
from contextlib import redirect_stdout, redirect_stderr
from scipy.sparse import csr_array
from sklearn.metrics.pairwise import cosine_similarity

from src.core.embedder import AutoModelEmbedder, BGEM3Embedder, MilvusBGEM3Embedder, DenseEmbedder, SparseEmbedder # adjust the import path

TEST_TEXTS = ["The quick brown fox jumps over the lazy dog."] * 4

class TestEmbedders(unittest.TestCase):

    def run_embedder_test(self, embedder_class, name, *args, **kwargs):
        buffer_out = io.StringIO()
        buffer_err = io.StringIO()

        with redirect_stdout(buffer_out), redirect_stderr(buffer_err):
            embedder = embedder_class(*args, **kwargs)
            _ = embedder.embed(TEST_TEXTS)

        stdout_output = buffer_out.getvalue()
        stderr_output = buffer_err.getvalue()

        print(f"\n=== {name} STDOUT ===\n{stdout_output}")
        print(f"=== {name} STDERR ===\n{stderr_output}")

    def test_automodel_embedder(self):
        
        self.run_embedder_test(AutoModelEmbedder, "AutoModelEmbedder", "sentence-transformers/all-MiniLM-L6-v2")

    def test_bgem3_embedder(self):
        self.run_embedder_test(BGEM3Embedder, "BGEM3Embedder", "BAAI/bge-m3", use_fp16=False)

    def test_milvus_bgem3_embedder(self):
        self.run_embedder_test(MilvusBGEM3Embedder, "MilvusBGEM3Embedder")

    def test_dense_embedder(self):
        # Use the factory method to create a DenseEmbedder
        embedder = DenseEmbedder.from_default("sentence-transformers/all-MiniLM-L6-v2")
        self.assertIsInstance(embedder, DenseEmbedder)
        self.assertIsInstance(embedder, AutoModelEmbedder)
        
        # Test embedding
        embeddings = embedder.embed(TEST_TEXTS)
        self.assertIsInstance(embeddings, list)
        self.assertEqual(len(embeddings), len(TEST_TEXTS))

    def test_sparse_embedder(self):
        # Use the factory method to create a SparseEmbedder
        embedder = SparseEmbedder.from_default("BAAI/bge-m3")
        self.assertIsInstance(embedder, SparseEmbedder)
        self.assertIsInstance(embedder, BGEM3Embedder)
        
        # Test embedding
        embeddings = embedder.embed(TEST_TEXTS)
        self.assertIsInstance(embeddings, csr_array)
        self.assertEqual(embeddings.shape[0], len(TEST_TEXTS))

    def test_similar_sentence_embedding(self):
        '''
        Test the similarity of sentence embedding.
        The sentence are similar, so the embedding should be similar.
        The embedding should be similar for all embedders.
        '''
        sentence_1 = "æ˜¨å¤©å‚æ™šï¼Œæˆ‘ç¨è‡ªèµ°åœ¨æ²³é‚Šï¼Œçœ‹è‘—å¾®é¢¨æ‹‚éæ°´é¢ï¼Œå¤•é™½çš„é¤˜æš‰æ˜ ç…§è‘—å¤©ç©ºï¼Œå¿ƒä¸­å……æ»¿äº†å¹³éœèˆ‡æ·¡æ·¡çš„æ„Ÿå‚·ã€‚"
        sentence_2 = "æ˜¨å¤©å‚æ™šï¼Œæˆ‘ä¸€å€‹äººåœ¨æ²³é‚Šæ•£æ­¥ï¼Œå¾®é¢¨è¼•è¼•å¹éæ°´é¢ï¼Œå¤•é™½çš„å…‰è¼æŸ“ç´…äº†å¤©ç©ºï¼Œå¿ƒè£¡æ¹§èµ·ä¸€ç¨®å¹³éœåˆæ·¡æ·¡çš„æƒ†æ‚µã€‚"

        # Also test with a very different sentence for comparison
        sentence_different = "ä»Šå¤©æ—©ä¸Šï¼Œæˆ‘åœ¨è¾¦å…¬å®¤è£¡å·¥ä½œï¼Œé›»è…¦è¢å¹•é¡¯ç¤ºè‘—å„ç¨®æ•¸æ“šï¼Œç©ºèª¿çš„å†·é¢¨å¹è‘—ï¼Œå¿ƒè£¡æƒ³è‘—ä¸‹åˆçš„æœƒè­°ã€‚"

        # Test AutoModelEmbedder
        embedder1 = AutoModelEmbedder("sentence-transformers/all-MiniLM-L6-v2")
        embeddings1 = embedder1.embed([sentence_1, sentence_2, sentence_different])
        
        # Test BGEM3Embedder
        embedder2 = BGEM3Embedder("BAAI/bge-m3", use_fp16=False)
        embeddings2 = embedder2.embed([sentence_1, sentence_2, sentence_different])
        
        # Test MilvusBGEM3Embedder
        embedder3 = MilvusBGEM3Embedder()
        embeddings3 = embedder3.embed([sentence_1, sentence_2, sentence_different])
        
        # Test DenseEmbedder
        embedder4 = DenseEmbedder.from_default("sentence-transformers/all-MiniLM-L6-v2")
        embeddings4 = embedder4.embed([sentence_1, sentence_2, sentence_different])
        
        # Test SparseEmbedder
        embedder5 = SparseEmbedder.from_default("BAAI/bge-m3")
        embeddings5 = embedder5.embed([sentence_1, sentence_2, sentence_different])

        # Basic assertions to ensure embeddings are generated
        self.assertIsInstance(embeddings1, list)
        self.assertEqual(len(embeddings1), 3)
        self.assertIsInstance(embeddings2, csr_array)
        self.assertEqual(embeddings2.shape[0], 3)
        self.assertIsInstance(embeddings3, csr_array)
        self.assertEqual(embeddings3.shape[0], 3)
        self.assertIsInstance(embeddings4, list)
        self.assertEqual(len(embeddings4), 3)
        self.assertIsInstance(embeddings5, csr_array)
        self.assertEqual(embeddings5.shape[0], 3)
        
        # Compute similarities for AutoModelEmbedder (dense vectors)
        emb1_array = np.array(embeddings1)
        similarity_similar_1 = cosine_similarity([emb1_array[0]], [emb1_array[1]])[0][0]
        similarity_different_1 = cosine_similarity([emb1_array[0]], [emb1_array[2]])[0][0]
        
        # Compute similarities for BGEM3Embedder (sparse vectors)
        similarity_similar_2 = cosine_similarity(embeddings2[0:1], embeddings2[1:2])[0][0]
        similarity_different_2 = cosine_similarity(embeddings2[0:1], embeddings2[2:3])[0][0]
        
        # Compute similarities for MilvusBGEM3Embedder (sparse vectors)
        similarity_similar_3 = cosine_similarity(embeddings3[0:1], embeddings3[1:2])[0][0]
        similarity_different_3 = cosine_similarity(embeddings3[0:1], embeddings3[2:3])[0][0]
        
        # Compute similarities for DenseEmbedder (dense vectors)
        similarity_similar_4 = cosine_similarity(embeddings4[0:1], embeddings4[1:2])[0][0]
        similarity_different_4 = cosine_similarity(embeddings4[0:1], embeddings4[2:3])[0][0]
        
        # Compute similarities for SparseEmbedder (sparse vectors)
        similarity_similar_5 = cosine_similarity(embeddings5[0:1], embeddings5[1:2])[0][0]
        similarity_different_5 = cosine_similarity(embeddings5[0:1], embeddings5[2:3])[0][0]
        
        print(f"\n=== Similarity Results ===")
        print(f"AutoModelEmbedder - Similar sentences: {similarity_similar_1:.4f}, Different sentences: {similarity_different_1:.4f}")
        print(f"BGEM3Embedder - Similar sentences: {similarity_similar_2:.4f}, Different sentences: {similarity_different_2:.4f}")
        print(f"MilvusBGEM3Embedder - Similar sentences: {similarity_similar_3:.4f}, Different sentences: {similarity_different_3:.4f}")
        print(f"DenseEmbedder - Similar sentences: {similarity_similar_4:.4f}, Different sentences: {similarity_different_4:.4f}")
        print(f"SparseEmbedder - Similar sentences: {similarity_similar_5:.4f}, Different sentences: {similarity_different_5:.4f}")
        
        # Assert that similar sentences have higher similarity than different sentences
        self.assertGreater(similarity_similar_1, similarity_different_1, 
                          f"AutoModelEmbedder: Similar sentences ({similarity_similar_1:.4f}) should be more similar than different sentences ({similarity_different_1:.4f})")
        self.assertGreater(similarity_similar_2, similarity_different_2,
                          f"BGEM3Embedder: Similar sentences ({similarity_similar_2:.4f}) should be more similar than different sentences ({similarity_different_2:.4f})")
        self.assertGreater(similarity_similar_3, similarity_different_3,
                          f"MilvusBGEM3Embedder: Similar sentences ({similarity_similar_3:.4f}) should be more similar than different sentences ({similarity_different_3:.4f})")
        self.assertGreater(similarity_similar_4, similarity_different_4,
                          f"DenseEmbedder: Similar sentences ({similarity_similar_4:.4f}) should be more similar than different sentences ({similarity_different_4:.4f})")
        self.assertGreater(similarity_similar_5, similarity_different_5,
                          f"SparseEmbedder: Similar sentences ({similarity_similar_5:.4f}) should be more similar than different sentences ({similarity_different_5:.4f})")
        
        # Assert that similar sentences have reasonably high similarity (typically > 0.7 for good models)
        self.assertGreater(similarity_similar_1, 0.7, 
                          f"AutoModelEmbedder: Similar sentences should have high similarity (> 0.7), got {similarity_similar_1:.4f}")
        self.assertGreater(similarity_similar_2, 0.5,  # Sparse embeddings might have lower similarity
                          f"BGEM3Embedder: Similar sentences should have reasonable similarity (> 0.5), got {similarity_similar_2:.4f}")
        self.assertGreater(similarity_similar_3, 0.5,  # Sparse embeddings might have lower similarity
                          f"MilvusBGEM3Embedder: Similar sentences should have reasonable similarity (> 0.5), got {similarity_similar_3:.4f}")
        self.assertGreater(similarity_similar_4, 0.7, 
                          f"DenseEmbedder: Similar sentences should have high similarity (> 0.7), got {similarity_similar_4:.4f}")
        self.assertGreater(similarity_similar_5, 0.5,  # Sparse embeddings might have lower similarity
                          f"SparseEmbedder: Similar sentences should have reasonable similarity (> 0.5), got {similarity_similar_5:.4f}")
        
        print(f"âœ… All similarity tests passed!")

    def test_chinese_short_vs_long_content_bias(self):
        '''
        Test Chinese short vs long content bias specifically.
        Compare two long descriptive contents with one short keyword to see
        if short content gets over-represented in embeddings.
        '''
        # One short Chinese keyword
        short_chinese = ["æ©Ÿå™¨å­¸ç¿’"]
        
        # Two longer descriptive Chinese contents about the same topic
        long_chinese_1 = ["å‚³çµ±çš„æ¨è–¦ç³»çµ±ä¸»è¦ä¾è³´æ–¼åˆ†ææ•¸æ“šå’Œæ©Ÿå™¨å­¸ç¿’ç®—æ³•ï¼Œä¸¦ç”±ç³»çµ±å–®æ–¹é¢å‘ä½¿ç”¨è€…æ¨æ’­ã€‚å°è©±å¼æ¨è–¦ç³»çµ±å‰‡å¯ä»¥ç›´æ¥æ¥å—ä¾†è‡ªä½¿ç”¨è€…ä¸»å‹•æä¾›çš„è³‡è¨Šï¼Œè€Œç³»çµ±ä¹Ÿèƒ½é€éæ–‡å­—å°é …ç›®é€²è¡Œæ¨è–¦ï¼Œçµ¦äºˆæœ€ç›´æ¥çš„å¹«åŠ©ã€‚åœ¨å°è©±å¼æ¨è–¦ç³»çµ±ï¼ˆConversational Recommender System, CRSï¼‰ä¸­ä½¿ç”¨å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLarge Language Model, LLMï¼‰èƒ½ç²å¾—è¨±å¤šå‚³çµ±æ¨¡å‹ç„¡æ³•æ“æœ‰çš„å„ªå‹¢ ã€‚é¦–å…ˆï¼ŒLLMçš„ç³»çµ±ä¸éœ€è¦ç¶“éè¨“ç·´å³å¯å±•ç¾å‡ºè‰²çš„æ€§èƒ½ï¼Œèƒ½å¤ è§£æ±ºå†·å•Ÿå‹•å•é¡Œã€‚å…¶æ¬¡ï¼ŒLLMçš„æ³›ç”¨æ€§åŠå¯æ“´å±•æ€§æ¥µé«˜ï¼Œèƒ½é©æ‡‰æˆ–å°å…¥åˆ°å„ç¨®æ‡‰ç”¨å ´æ™¯ã€‚å¤§å¤šæ•¸ä»¥å¾€çš„ç ”ç©¶åå‘æ–¼å¾å¤§é‡çš„ç‰©ä»¶ä¸­æ¨è–¦å‡ºä¸€å€‹æœ€ç›¸é—œçš„å…§å®¹ï¼Œé€™è¼ƒé©åˆä½¿ç”¨æª¢ç´¢å¢å¼·ç”Ÿæˆï¼ˆRetrieval Augmented Generation, RAGï¼‰æŠ€è¡“ï¼›æˆ‘å€‘çš„ç ”ç©¶è‘—é‡æ–¼å¾å°‘é‡çš„ç‰©ä»¶ä¸­æ¨è–¦ä¸€å€‹æœ€é©åˆçš„å…§å®¹ï¼Œä¸¦å¼·èª¿æ‡‰ä¾æ“šç—… å› ä¾†æ¨è–¦è—¥æ–¹ã€‚æœ¬ç ”ç©¶é¦–æ¬¡å˜—è©¦ä»¥å¤±çœ æ‚£è€…çš„ä¸­è—¥æ–¹æ¨è–¦ä½œç‚ºä»»å‹™ç›®æ¨™ï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡èƒ½åŠ›å‡ºè‰²çš„gemini-1.5-flashæ¨¡æ“¬ä¸¦ç”Ÿæˆç—…æ‚£èˆ‡ä¸­é†«å¸«ä¹‹é–“çš„å°è©±ã€‚æˆ‘å€‘æå‡ºHint Moduleä¾†å°å…¥ç”Ÿ ç†é‡æ¸¬åŠä¸­é†«å•è¨ºæŠ€å·§ï¼Œé€éåµæ¸¬ç‰¹å®šå­—ä¸²ä¾†è§¸ç™¼ç³»çµ±æ©Ÿåˆ¶ï¼Œçµ¦äºˆLLMé¡å¤–çš„æç¤ºè¨Šæ¯è—‰æ­¤å½±éŸ¿å®ƒçš„è¼¸å‡ºçµæœã€‚æˆ‘å€‘çš„å¯¦é©—çµæœé¡¯ç¤ºï¼Œæ­¤æ–¹æ³•å¯ç”Ÿæˆå¯«å¯¦çš„è‡ªè¿°ï¼Œèƒ½è¢«è¦–ä½œç‚ºè‰¯å¥½çš„å°è©±ç¯„ ä¾‹ï¼Œä¸¦åœ¨åç¨®ä¸­è—¥æ–¹çš„æ¨è–¦ä»»å‹™ä¸­ï¼Œå¯å¾—åˆ°å…«æˆä»¥ä¸Šçš„æº–ç¢ºç‡åŠMacro-F1æˆç¸¾ã€‚å…¶ä¸­Hint Moduleèƒ½é¡¯è‘—åœ°æ”¹å–„å¤šè¼ªå°è©±å¾Œçš„æˆç¸¾è¡¨ç¾ (p-value < 0.01)ã€‚æœ€å¾Œæˆ‘å€‘ä¹Ÿä»¥ä¸­é†«å­¸çš„å„é …è§€é»é€²è¡Œåˆ†æï¼Œé€éè¦–è¦ºåŒ–çš„åœ–è¡¨å‘ˆç¾å‡ºå„å€‹è—¥æ–¹ä¹‹é–“åˆ†å¸ƒä¸Šçš„é—œè¯æ€§ï¼Œä»¥å¾—åˆ°æ›´å…¨é¢åŠæ¸…æ™°çš„ç­è§£ã€‚å¯¦é©—çµæœå±•ç¤ºäº†ä»¥LLMæ‰“é€ çš„ä¸­è—¥æ–¹æ¨è–¦ç³»çµ±æ“æœ‰å‚‘å‡ºçš„åŸºç¤èƒ½åŠ›ï¼Œä¸¦æ“æœ‰çµ•ä½³çš„å¯æ“´å±• æ€§ã€‚"]
        long_chinese_2 = ["æ˜¯å¦å·²æœ‰ç ”ç©¶æ¢è¨å°‡å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLarge Language Models, LLMsï¼‰æ‡‰ç”¨æ–¼å°è©±å¼æ¨è–¦ç³»çµ±ï¼ˆConversational Recommender Systems, CRSï¼‰ï¼Œä»¥è§£æ±ºå†·å•Ÿå‹•å•é¡Œï¼Œä¸¦å¯¦ä½œåœ¨ä¸­é†«è—¥æ–¹æ¨è–¦ï¼ˆç‰¹åˆ¥æ˜¯é‡å°å¤±çœ æ‚£è€…ï¼‰ä¸Šï¼Œé€²è¡Œå¤šè¼ªå•ç­”ã€å¼•å°å¼å°è©±ä»¥åŠçµåˆä¸­é†«è¨ºç™‚æŠ€å·§ä¾†æå‡æ¨è–¦æº–ç¢ºç‡ï¼Ÿ"]
        
        # Different Chinese content for comparison
        different_chinese = ["ä»Šå¤©å¤©æ°£æ™´æœ—ï¼Œæ°£æº«25åº¦ï¼Œé©åˆå¤–å‡ºæ´»å‹•ã€‚"]
        
        print(f"\n=== Testing Chinese Short vs Long Content Bias ===")
        print(f"Short: {short_chinese[0]}")
        print(f"Long 1: {long_chinese_1[0][:100]}...")
        print(f"Long 2: {long_chinese_2[0]}")
        print(f"Different: {different_chinese[0]}")
        print(f"\nRAG Scenario:")
        print(f"- Long 1: Document content (stored in database)")
        print(f"- Long 2: Detailed user query")
        print(f"- Short: Simple keyword query")
        print(f"- Different: Unrelated content")
        
        # Test all embedders
        embedders = [
            ("AutoModelEmbedder", AutoModelEmbedder("sentence-transformers/all-MiniLM-L6-v2")),
            ("BGEM3Embedder", BGEM3Embedder("BAAI/bge-m3", use_fp16=False)),
            ("MilvusBGEM3Embedder", MilvusBGEM3Embedder()),
            ("DenseEmbedder", DenseEmbedder.from_default("sentence-transformers/all-MiniLM-L6-v2")),
            ("SparseEmbedder", SparseEmbedder.from_default("BAAI/bge-m3"))
        ]
        
        # Collect all results first
        results = []
        
        for name, embedder in embedders:
            print(f"\n--- {name} (Chinese) ---")
            
            try:
                # Get embeddings
                short_embeddings = embedder.embed(short_chinese)
                long_embeddings_1 = embedder.embed(long_chinese_1)
                long_embeddings_2 = embedder.embed(long_chinese_2)
                different_embeddings = embedder.embed(different_chinese)
                
                # Compute similarities
                if isinstance(short_embeddings, list):
                    # Dense embeddings
                    short_array = np.array(short_embeddings)
                    long_array_1 = np.array(long_embeddings_1)
                    long_array_2 = np.array(long_embeddings_2)
                    different_array = np.array(different_embeddings)
                    
                    # RAG-relevant similarities
                    sim_doc_detailed = cosine_similarity([long_array_1[0]], [long_array_2[0]])[0][0]  # Document vs Detailed Query
                    sim_doc_short = cosine_similarity([long_array_1[0]], [short_array[0]])[0][0]     # Document vs Short Query
                    sim_detailed_short = cosine_similarity([long_array_2[0]], [short_array[0]])[0][0] # Detailed Query vs Short Query
                    
                    # vs Different content
                    sim_doc_different = cosine_similarity([long_array_1[0]], [different_array[0]])[0][0]     # Document vs Different
                    sim_detailed_different = cosine_similarity([long_array_2[0]], [different_array[0]])[0][0] # Detailed Query vs Different
                    sim_short_different = cosine_similarity([short_array[0]], [different_array[0]])[0][0]    # Short Query vs Different
                    
                else:
                    # Sparse embeddings
                    sim_doc_detailed = cosine_similarity(long_embeddings_1[0:1], long_embeddings_2[0:1])[0][0]  # Document vs Detailed Query
                    sim_doc_short = cosine_similarity(long_embeddings_1[0:1], short_embeddings[0:1])[0][0]     # Document vs Short Query
                    sim_detailed_short = cosine_similarity(long_embeddings_2[0:1], short_embeddings[0:1])[0][0] # Detailed Query vs Short Query
                    
                    # vs Different content
                    sim_doc_different = cosine_similarity(long_embeddings_1[0:1], different_embeddings[0:1])[0][0]     # Document vs Different
                    sim_detailed_different = cosine_similarity(long_embeddings_2[0:1], different_embeddings[0:1])[0][0] # Detailed Query vs Different
                    sim_short_different = cosine_similarity(short_embeddings[0:1], different_embeddings[0:1])[0][0]    # Short Query vs Different
                
                # Store results
                result = {
                    'name': name,
                    'sim_doc_detailed': sim_doc_detailed,
                    'sim_doc_short': sim_doc_short,
                    'sim_detailed_short': sim_detailed_short,
                    'sim_doc_different': sim_doc_different,
                    'sim_detailed_different': sim_detailed_different,
                    'sim_short_different': sim_short_different,
                    'success': True
                }
                
                print(f"RAG Similarity Matrix:")
                print(f"                    | Document | Detailed | Short   | Different")
                print(f"--------------------|----------|----------|---------|----------")
                print(f"Document            |   1.0000 | {sim_doc_detailed:.4f}  | {sim_doc_short:.4f} | {sim_doc_different:.4f}")
                print(f"Detailed Query      | {sim_doc_detailed:.4f}  |   1.0000 | {sim_detailed_short:.4f} | {sim_detailed_different:.4f}")
                print(f"Short Query         | {sim_doc_short:.4f}  | {sim_detailed_short:.4f} |   1.0000 | {sim_short_different:.4f}")
                print(f"Different Content   | {sim_doc_different:.4f}  | {sim_detailed_different:.4f} | {sim_short_different:.4f} |   1.0000")
                
                print(f"\nKey RAG Metrics:")
                print(f"Document vs Detailed Query: {sim_doc_detailed:.4f} (Should be HIGH - relevant content)")
                print(f"Document vs Short Query:    {sim_doc_short:.4f} (Should be HIGH - relevant content)")
                print(f"Detailed vs Short Query:    {sim_detailed_short:.4f} (Should be HIGH - same topic)")
                print(f"Document vs Different:      {sim_doc_different:.4f} (Should be LOW - irrelevant)")
                print(f"Detailed vs Different:      {sim_detailed_different:.4f} (Should be LOW - irrelevant)")
                print(f"Short vs Different:         {sim_short_different:.4f} (Should be LOW - irrelevant)")
                
                # Calculate bias indicators
                short_query_bias = sim_short_different - min(sim_doc_short, sim_detailed_short)
                detailed_query_advantage = sim_doc_detailed - sim_doc_short
                
                print(f"\nBias Analysis:")
                print(f"Short Query Bias: {short_query_bias:.4f} (Positive = short query more similar to different content)")
                print(f"Detailed Query Advantage: {detailed_query_advantage:.4f} (Positive = detailed query better than short)")
                
                # Check for potential bias issues
                if sim_doc_short < 0.5:
                    print(f"ğŸš¨ CRITICAL: {name} shows very low similarity between document and short query")
                    print(f"   This indicates severe short query bias - short queries won't find relevant documents")
                elif sim_doc_short < 0.6:
                    print(f"âš ï¸  WARNING: {name} shows low similarity between document and short query")
                    print(f"   This suggests short queries may not retrieve relevant documents effectively")
                elif sim_doc_short < 0.7:
                    print(f"ğŸ“Š MODERATE: {name} shows moderate similarity between document and short query")
                    print(f"   This may indicate some short query bias")
                else:
                    print(f"âœ… GOOD: {name} shows good similarity between document and short query")
                    print(f"   This suggests minimal short query bias")
                
                if short_query_bias > 0:
                    print(f"ğŸš¨ CRITICAL: {name} shows short queries are more similar to different content than relevant content")
                    print(f"   This will cause retrieval to return irrelevant results for short queries")
                
            except Exception as e:
                print(f"âŒ ERROR: {name} failed with error: {str(e)}")
                result = {
                    'name': name,
                    'success': False,
                    'error': str(e)
                }
            
            results.append(result)
        
        # Now show summary and run assertions
        print(f"\n=== SUMMARY OF ALL EMBEDDERS ===")
        print(f"{'Embedder':<20} {'Doc-Detailed':<12} {'Doc-Short':<10} {'Det-Short':<10} {'Short-Diff':<10} {'Bias':<8} {'Status':<10}")
        print(f"{'-'*90}")
        
        for result in results:
            if result['success']:
                short_query_bias = result['sim_short_different'] - min(result['sim_doc_short'], result['sim_detailed_short'])
                status = "âœ… GOOD" if result['sim_doc_short'] >= 0.7 and short_query_bias <= 0 else \
                        "ğŸ“Š MODERATE" if result['sim_doc_short'] >= 0.6 else \
                        "âš ï¸ WARNING" if result['sim_doc_short'] >= 0.5 else "ğŸš¨ CRITICAL"
                
                print(f"{result['name']:<20} {result['sim_doc_detailed']:<12.4f} {result['sim_doc_short']:<10.4f} "
                      f"{result['sim_detailed_short']:<10.4f} {result['sim_short_different']:<10.4f} "
                      f"{short_query_bias:<8.4f} {status:<10}")
            else:
                print(f"{result['name']:<20} {'ERROR':<12} {'ERROR':<10} {'ERROR':<10} {'ERROR':<10} {'ERROR':<8} âŒ FAILED")
        
        # Now run assertions for all successful embedders
        print(f"\n=== ASSERTION RESULTS ===")
        failed_assertions = []
        
        for result in results:
            if result['success']:
                # Assert that document should be more similar to relevant queries than to different content
                if result['sim_doc_short'] <= result['sim_doc_different']:
                    failed_assertions.append(f"{result['name']}: Document should be more similar to short query than to different content")
                
                if result['sim_doc_detailed'] <= result['sim_detailed_different']:
                    failed_assertions.append(f"{result['name']}: Document should be more similar to detailed query than to different content")
                
                # Assert that short query should be more similar to relevant content than to different content
                if result['sim_doc_short'] <= result['sim_short_different']:
                    failed_assertions.append(f"{result['name']}: Short query should be more similar to relevant document than to different content")
                
                if result['sim_detailed_short'] <= result['sim_short_different']:
                    failed_assertions.append(f"{result['name']}: Short query should be more similar to detailed query than to different content")
        
        if failed_assertions:
            print(f"âŒ FAILED ASSERTIONS:")
            for assertion in failed_assertions:
                print(f"   - {assertion}")
            # Don't raise exception, just report
        else:
            print(f"âœ… ALL ASSERTIONS PASSED")
        
        print(f"\n=== RAG System Recommendations ===")
        print(f"Based on the results:")
        print(f"1. Choose embedders with high Doc-Short similarity for better short query retrieval")
        print(f"2. Avoid embedders with positive Short Query Bias (short queries more similar to irrelevant content)")
        print(f"3. Consider query expansion for embedders with low Doc-Short similarity")
        print(f"4. Use hybrid search (dense + keyword) for problematic embedders")
        print(f"5. Implement reranking with longer context for final results")

if __name__ == "__main__":
    unittest.main()
